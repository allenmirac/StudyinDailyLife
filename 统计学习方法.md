其实这个是第二次看了，重新在看另外一本书，《统计学习方法》。
迷茫，不知道看这些还有什么用，但是去看训练代码还是看不懂，到底怎么回事啊，不知道为什么要加那些模块，害(┬┬﹏┬┬)
快速过一遍这本书，然后回到论文上面来	<(￣︶￣)↗[GO!]

## 统计学习方法读书笔记

不懂就记下来

## 标注问题

输入变量与输出变量均为连续变量的预测问题称为回归问题，输出变量为有限个离散变量的预测问题称为分类问题。

输入变量与输出变量均为变量序列的预测问题称为标注问题。

**标注问题**之所以被称为**“标注”**，是因为这类问题的核心任务是为输入序列中的每个元素**分配一个标签（Label）**，即“标注”这些元素。以下是更直观的解释：

------

### 1. 标注的核心概念

标注问题的任务是**给每个输入元素分配一个特定的标签**，这就像在输入序列的每个位置上“贴标签”一样，类似我们日常在地图上标记位置或者给照片添加注释。

例如：

- 输入：一个句子的词序列$$[w_1, w_2, w_3]$$
- 输出：对应的词性标签序列 $$[tag_1, tag_2, tag_3]$$

在这个过程中，“标注”指的是为每个单词找到其对应的标签（如名词、动词等）。

------

### 2. 为什么是“标注”而不是“预测”

尽管标注问题也是一种预测问题，但它与普通的回归或分类问题不同，其显著特点是：

1. **输入和输出都是序列**：普通的预测通常只针对单一变量（如分类问题），而标注问题需要为序列中每个元素进行预测。
2. **标签的上下文依赖性**：标注不仅要根据输入的单个元素来预测标签，还要考虑其上下文。例如，句子中的一个单词的词性，可能会依赖于前后词的词性。

由于这些特性，更贴切的描述是“为每个序列元素**打标签**”——这就是“标注”这个词的来源。

------

### 3. 典型例子：NLP中的标注问题

以自然语言处理中的**词性标注（POS Tagging）**为例：

- 输入序列：
   *我/爱/学习*
- 输出序列：
   *代词(PRON)/动词(VERB)/动词(VERB)*

这里的“标注”过程是：为句子中的每个词分配一个对应的词性标签。

------

### 4. 其他“标注”的类比

“标注”这个概念可以推广到很多领域，以下是几个比喻，帮助理解：

- **地图标注**：给每个地理位置加一个标签（如学校、医院、商店等）。
- **时间序列标注**：给每个时间点的数据加一个状态标签（如天气预测：晴天/雨天）。
- **语音处理**：为每一段语音分配一个对应的文字（如语音转文字系统）。

------

### **总结**

标注问题的本质在于为**输入序列中的每个元素打标签**，而不是仅仅预测一个整体结果。这种任务的应用场景广泛，因此被统一称为“标注问题”。

## 如何理解正则化来防止模型过拟合

理解正则化如何防止模型过拟合，可以从以下几个方面进行分析：

### 1. **过拟合的概念**
过拟合是指模型在训练数据上表现良好，但在未见的数据（测试数据）上表现不佳的现象。过拟合通常发生在模型过于复杂时，即模型具有过多的参数或者特征，使其能够“记住”训练数据中的噪声而不是学习到数据的真实模式。

### 2. **正则化的基本原理**
正则化通过在损失函数中加入惩罚项，来限制模型的复杂度。常见的正则化方法有L1（Lasso）和L2（Ridge）正则化，它们分别通过不同方式惩罚模型参数。

- **L1 正则化**：增加模型参数绝对值的和作为惩罚项，促使一些参数为零，从而进行特征选择。这有助于去除不重要的特征，使模型更加简洁。

- **L2 正则化**：增加模型参数平方和作为惩罚项，鼓励模型参数的整体减小。这意味着即使模型使用了所有特征，参数的值也不会过大，从而减小对训练数据的敏感性。

### 3. **通过增加惩罚项调整损失函数**
在正则化的情况下，模型的损失函数通常被修改为：

$$
\text{Loss} = \text{Loss}_{\text{original}} + \lambda \cdot \text{Penalty}
$$

其中，$$\lambda$$是正则化参数，用于控制惩罚项的强度。较大$$\lambda$$的值会增加惩罚，使得模型更加简单，从而降低过拟合的风险。

### 4. **效果和直观理解**
- **模型复杂度**：正则化相当于在优化过程中引入了对模型复杂度的约束，促使模型在选择特征和学习参数时更加谨慎。这种谨慎使得模型更有可能学习到更具代表性的特征，而不是训练数据中的偶然模式。

- **泛化能力**：通过正则化，模型的泛化能力得到提升，能更好地适应新的、未见的数据。这是因为正则化帮助模型更关注数据的整体结构，而非个别噪声或异常值。

### 5. **调节与验证**
正则化参数的选择至关重要。通过交叉验证等技术，可以找到最佳的$$\lambda\)值，使得模型在训练集和验证集上都能保持良好的性能，从而达到防止过拟合的效果。

### 总结
正则化通过惩罚模型复杂度，有效降低了模型对训练数据的过度拟合，使得模型在未见数据上表现更加稳健。理解这一过程有助于在实际建模中选择合适的正则化策略，优化模型的性能。

## L1正则化可以让模型参数的值为0的原因

L1正则化能够促使一些模型参数 $$ w_i $$ 的值为零的原理主要体现在其损失函数的优化过程中。以下是对这一原理的详细解释及示例。

### 原理解释

L1正则化通过在损失函数中加入参数的绝对值之和作为惩罚项，促使模型参数的某些值趋近于零。其损失函数形式为：

$$
\text{Loss} = \text{Loss}_{\text{original}} + \lambda \cdot \sum_{i=1}^{n} |w_i|
$$

这里，$$ \lambda $$是正则化强度的超参数，控制惩罚项的影响力。

1. **绝对值的性质**：绝对值函数在原点是不可导的，这意味着当优化算法（如梯度下降）试图更新参数 $$ w_i \) 时，某些参数可能会直接达到零。这种情况通常发生在参数的更新过程中，惩罚项使得某些参数的更新幅度减小到零。

2. **目标函数的几何形状**：L1正则化的惩罚项形成的等高线是菱形（或正方形），与损失函数的等高线相交时，往往会在坐标轴上接触，这意味着模型的某些参数将被推至零。这是因为在最优化过程中，绝对值函数的“尖角”会导致某些参数在最优解处为零。

3. **凸优化的效果**：L1正则化的目标函数是一个凸函数，优化时容易收敛到局部最优解，进而有可能出现部分参数被收缩到零的现象。

### 示例

以下是一个简单的例子，说明如何通过L1正则化促使参数为零。

#### 例子设定
假设我们有一个线性回归模型，其模型形式为：

$$
y = w_1 x_1 + w_2 x_2 + b
$$

我们用一个小的数据集来训练模型：

| $$ x_1 $$ | $$ x_2 $$ | $$ y $$ |
| --------- | --------- | ------- |
| 1         | 2         | 3       |
| 2         | 3         | 5       |
| 3         | 4         | 7       |
| 4         | 5         | 9       |
| 5         | 6         | 11      |

#### 步骤
1. **损失函数**：
   - 原始损失函数（均方误差）为：
   $$
   \text{Loss}_{\text{original}} = \frac{1}{n} \sum (y_i - (w_1 x_{1,i} + w_2 x_{2,i} + b))^2
   $$

2. **加入L1正则化**：
   
   - 假设我们设置 $$ \lambda = 0.1 $$，那么加入L1正则化后的损失函数为：
   $$
   \text{Loss} = \frac{1}{n} \sum (y_i - (w_1 x_{1,i} + w_2 x_{2,i} + b))^2 + 0.1 (|w_1| + |w_2|)
   $$
   
3. **训练过程**：
   - 在使用梯度下降等优化算法进行训练时，更新参数 $$ w_1 $$ 和 $$ w_2 $$ 的步骤包括计算原始损失的梯度和L1惩罚的梯度。
   - 由于L1正则化的特性，当优化算法调整 $$ w_1 $$ 和 $$ w_2 $$ 时，某些参数的值可能会被推到零。例如，如果 $$ w_1 $$ 的影响相对较小，优化过程中可能会发现保持$$ w_1 = 0 $$ 能够显著降低损失。

#### 结果
经过多次迭代，最终可能得到  $$$w_1 = 0$$$ 和$$ w_2 = 2 $$，这意味着在这个特定的训练中，特征 $$ x_1$$$ 对目标变量 $$ y $$ 的预测并没有显著贡献，模型将其完全忽略。

### 总结
L1正则化通过惩罚参数的绝对值，促使某些参数的值为零，这主要源于其损失函数的几何特性和优化过程中的特性。通过训练，模型能够自动选择对预测最有用的特征，从而提高其在未见数据上的泛化能力。

### 代码示例

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Lasso
from sklearn.linear_model import LinearRegression

# 生成数据
np.random.seed(0)
X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])
y = np.array([3, 5, 7, 9, 11])

# 定义L1正则化强度
lambda_l1 = 0.1

# 绘制损失函数的等高线
def plot_contours(lambdas):
    w1_range = np.linspace(-5, 5, 100)
    w2_range = np.linspace(-5, 5, 100)
    W1, W2 = np.meshgrid(w1_range, w2_range)

    # 计算损失值
    loss = np.zeros(W1.shape)
    for i in range(len(X)):
        loss += (y[i] - (W1 * X[i, 0] + W2 * X[i, 1])) ** 2

    loss = loss / len(X) + lambdas * (np.abs(W1) + np.abs(W2))  # 添加L1惩罚

    plt.figure(figsize=(10, 8))
    contour = plt.contour(W1, W2, loss, levels=np.logspace(0, 4, 20), cmap='viridis')
    plt.clabel(contour, inline=True, fontsize=8)
    plt.title('Loss Contours with L1 Regularization')
    plt.xlabel('w1')
    plt.ylabel('w2')

    # 绘制L1惩罚的约束
    plt.plot([lambda_l1, -lambda_l1], [0, 0], 'r--', label='L1 constraint')
    plt.plot([0, 0], [lambda_l1, -lambda_l1], 'r--')
    plt.fill_betweenx(np.linspace(-lambda_l1, lambda_l1, 100), -lambda_l1, lambda_l1, alpha=0.1, color='red')

    plt.xlim(-5, 5)
    plt.ylim(-5, 5)
    plt.axhline(0, color='black', lw=0.5)
    plt.axvline(0, color='black', lw=0.5)
    plt.legend()
    plt.grid()
    plt.show()

# 训练线性回归模型
model = LinearRegression()
model.fit(X, y)
print(f'Linear Regression Coefficients: {model.coef_}')

# 训练L1正则化的模型
lasso_model = Lasso(alpha=lambda_l1)
lasso_model.fit(X, y)
print(f'L1 Regularization Coefficients: {lasso_model.coef_}')

# 绘制等高线
plot_contours(lambda_l1)
```

Output

```shell
Linear Regression Coefficients: [1. 1.]
L1 Regularization Coefficients: [1.9500000e+00 8.8817842e-17]
```

这个输出的含义是，经过 **L1 正则化**（Lasso 回归）后，模型的回归系数为：

- **`1.9500000e+00`**：第一个特征 $$ x_1 $$ 的回归系数大约为 **1.95**，表示这个特征对预测目标 $$ y $$ 有较大的影响。
- **`8.8817842e-17`**：第二个特征 $$ x_2 $$ 的回归系数非常接近于 **0**，这个值可以被认为是数值精度误差。实际上，L1 正则化已经将该特征的系数压缩为 **0**，表明 $$ x_2 $$ 对目标值 $$ y $$ 几乎没有影响，模型忽略了这个特征。

---

#### 为什么第二个系数接近于 0？

这正是 **L1 正则化** 的作用！

- L1 正则化通过在损失函数中添加 $$ \lambda \sum |w_i| $$ 惩罚项，鼓励不重要的特征权重 $$ w $$ 接近 0 或直接为 0。
- 在这个例子中，模型通过正则化发现 $$ x_2 $$ 对预测目标 $$ y $$ 的影响较小，因此将其系数 $$ w_2 $$压缩到接近 0。

---

#### 数值解释
1. **`1.9500000e+00`**：
   - 指数形式表示 $$ 1.95 \times 10^0 = 1.95 $$，说明 $$ w_1 $$ 是接近 1.95 的非零值。

2. **`8.8817842e-17`**：
   - 指数形式表示 $$ 8.88 \times 10^{-17} $$，非常接近 0，是计算中的浮点数误差。
   - 实际意义上，它等价于 0，表示模型已经剔除了该特征。

---

#### 正则化的效果
- **普通线性回归**：
  不进行正则化的情况下，两个特征可能都会得到较大的非零系数。例如：
  ```
  Linear Regression Coefficients: [1. 1.]
  ```
  表示两个特征对 $$ y $$ 的贡献相等。

- **L1 正则化（Lasso）**：
  在 L1 正则化下，模型会自动选择对目标值影响大的特征，而忽略其他不重要的特征，可能得到：
  
  ```
  L1 Regularization Coefficients: [1.95 0.]
  ```
  表示 $$ x_2 $$ 对 $$ y $$ 几乎没有贡献，被压缩为 0。

---

#### 模型解释
最终，带 L1 正则化的模型公式可以写为：

$$
y = 1.95 \cdot x_1 + 0 \cdot x_2
$$

这说明模型完全依赖 $$ x_1 $$ 来预测 $$ y $$，从而实现了特征选择和模型的简化.

## 感知机

重新学习了下感知机的基础，自己实现了一遍代码，手算了下面的更新参数的过程，对感知机模型的了解更深入了。感知机学习的对偶形式还没有看完。

导师上次批评的基础是不是就是指这种，但是这种东西是否考虑的太深入了，不需要了解这么多内容，会用就可以，所以在犹豫是否像下面这样更新《统计学习方法》后续章节（整理要花好久的时间( •̀ ω •́ )✧）。论文任务依旧在压着(┬┬﹏┬┬)，还是继续快速看完书，论文也不能落下<(￣︶￣)↗[GO!]

感知机学习是机器学习中的一种经典算法，用于线性可分数据的分类，是二分类的线性分类模型，输入时实例的特征向量，输出可以取+1 和 -1二值。

### 例子

以下是一个简单的例子，帮助理解感知机学习的过程：

假设我们有一个二维平面上的数据集，分为两类：

- 类别 +1 （正类）：点 (2,3) 和 (3,4)
- 类别 −1 （负类）：点 (1,1) 和 (2,1)

目标是学习一个直线分类器，将这两类分开。感知机模型的假设形式为：

$$y = \text{sign}(w_1x_1 + w_2x_2 + b)$$

其中：

- $$w_1, w_2$$ 是感知机的权重；
- $$b$$ 是偏置；
- $${sign}(\cdot)$$ 是符号函数，用于确定分类。

------

### **感知机学习步骤**

1. **初始化参数**
    初始化$$w_1 = 0, w_2 = 0, b = 0$$。

2. **遍历样本并更新参数**
    对于每个样本 $$(x_1, x_2)$$ 和其对应的标签 y，根据以下规则更新权重和偏置：

   $$w \leftarrow w + \eta y x$$

   $$b \leftarrow b + \eta y$$

   其中，$$\eta$$ 是学习率（假设$$\eta = 1$$）。

3. **循环更新直到分类正确**
    不断重复以上更新，直到所有样本分类正确。

### 第1轮更新

初始参数：

$$w_1 = 0, \; w_2 = 0, \; b = 0$$

遍历样本并逐一更新：

1. **样本 (2,3),y=+1：**

   分类错误，更新参数：
   $$w_1 = 0 + 1 \cdot 2 = 2, w_2 = 0 + 1 \cdot 3 = 3, b = 0 + 1 \cdot 1 = 1$$

2. **样本 (1,1),y=−1：**

   z=2⋅1+3⋅1+1=6, y′=sign(6)=+1

   预测错误，更新参数：

   $$w_1\leftarrow w_1 + \eta y x_1 = 2 + 1 \cdot (-1) \cdot 1 = 1$$

   $$w_2\leftarrow w_2 + \eta y x_2 = 3 + 1 \cdot (-1) \cdot 1 = 2$$

   $$b \leftarrow b + \eta y = 1 + 1 \cdot (-1) = 0$$

   更新后参数为：

   $$w_1 = 1, \; w_2 = 2, \; b = 0$$

3. **样本 (3,4),y=+1(3, 4), y = +1：**

   z=1⋅3+2⋅4+0=11, y′=sign(11)=+1

   预测正确，无需更新。

4. **样本 (2,1),y=−1(2, 1), y = -1：**

   z=1⋅2+2⋅1+0=4, y′=sign(4)=+1

   预测错误，更新参数：

   $$w_1 \leftarrow w_1 + \eta y x_1 = 1 + 1 \cdot (-1) \cdot 2 = -1$$

   $$w_2 \leftarrow w_2 + \eta y x_2 = 2 + 1 \cdot (-1) \cdot 1 = 1$$

   $$b \leftarrow b + \eta y = 0 + 1 \cdot (-1) = -1$$

   更新后参数为：

   $$w_1 = -1, \; w_2 = 1, \; b = -1$$

------

### **第2轮遍历**

1. **样本 (2,3),y=+1(2, 3), y = +1：**

   $$z = -1 \cdot 2 + 1 \cdot 3 - 1 = 0, \quad y' = \text{sign}(0) = +1$$

   预测正确，无需更新。

2. **样本 (1,1),y=−1(1, 1), y = -1：**

   $$z = -1 \cdot 1 + 1 \cdot 1 - 1 = -1, \quad y' = \text{sign}(-1) = -1$$

   预测正确，无需更新。

3. **样本 (3,4),y=+1(3, 4), y = +1：**

   $$z = -1 \cdot 3 + 1 \cdot 4 - 1 = 0, \quad y' = \text{sign}(0) = +1$$

   预测正确，无需更新。

4. **样本 (2,1),y=−1(2, 1), y = -1：**

   $$z = -1 \cdot 2 + 1 \cdot 1 - 1 = -2, \quad y' = \text{sign}(-2) = -1$$

   预测正确，无需更新。

在 **默认情况下**，当 z=0 时，约定 sign(0)=+1。

------

### **分类器收敛**

在第2轮遍历后，所有样本均分类正确，最终分类器参数为：

$$w_1 = -1, \; w_2 = 1, \; b = -1$$

**最终分类器：**

$$y = \text{sign}(-x_1 + x_2 - 1)$$

对应的分割线为：

$$x_2 - x_1 - 1 = 0 \quad \text{或} \quad x_2 = x_1 + 1$$

### 更新权重过程的理解

更新权重的过程实际上是将分类超平面向误分类点的一侧移动，以减少误分类样本的符号距离。具体来说：

1. **误分类点的位置**：

   - 对于一个误分类点，其符号距离 $$y_i (\mathbf{w}^\top \mathbf{x}_i + b) \leq 0$$。这意味着当前分类超平面无法正确划分该点（例如，正类点在超平面负侧，或负类点在超平面正侧）。

2. **权重更新公式**：

   - 更新公式为： $$\mathbf{w} \leftarrow \mathbf{w} + \eta y_i \mathbf{x}_i$$ 其中，η\etaη 是学习率，$$y_i$$是标签，$$\mathbf{x}_i$$ 是误分类样本的特征。

3. **更新的直观含义**：

   - 如果$$y_i = 1$$（正类点被误分类为负类），更新方向为正向移动$$\mathbf{x}_i$$，将超平面向该点靠近。
   - 如果 $$y_i = -1$$（负类点被误分类为正类），更新方向为负向移动 $$\mathbf{x}_i$$，使超平面远离该点。

   这种调整使得误分类点在更新后更接近正确侧（即符号距离 $$y_i (\mathbf{w}^\top \mathbf{x}_i + b)$$ 增大）。

4. **偏置的作用**：

   - 偏置更新公式为：

     $$b \leftarrow b + \eta y_i$$

     - 这相当于平移超平面整体，而不改变其方向。
     - 偏置调整确保误分类点在更新后更加贴近正确分类侧。

5. **整体效果**：

   - 权重更新推动超平面朝向修正误分类点的方向移动。
   - 通过逐步调整，最终的分类超平面会使误分类样本越来越少，直到所有样本正确分类（或达到停止条件）。

### 学习策略损失函数

在上面的例子中，并没有使用损失函数。在感知机学习中，损失函数的选择决定了学习策略的优化目标。感知机使用的是**感知机损失函数**，这是专为线性分类问题设计的一种简单损失函数。

**第一种损失函数**：

感知机的损失函数为：

$$L(w, b) = -\sum_{i \in \mathcal{M}} y_i \cdot (w^\top x_i + b)$$

其中：

- M是所有被分类错误的样本集合；
- $$y_i$$是样本 i 的真实标签；
- $$w^\top x_i + b$$是样本的预测得分。

**关键点：**只有分类错误的样本才会产生损失。

**第二种损失函数**：

如果感知机的损失函数是所有误分类点到超平面 S的总距离，那么损失函数的形式会与几何距离相关。

### **基于误分类点的总距离损失函数**

如果损失函数是误分类点到超平面的总距离，则可以写为：

$$L(w, b) = \sum_{i \in \mathcal{M}} \frac{-y_i (w^\top x_i + b)}{\|w\|},$$

其中：

- M 是所有被误分类的样本集合；
- $$y_i (w^\top x_i + b) \leq 0$$表示样本 i 被误分类；
- 分子部分 $$-y_i (w^\top x_i + b)$$是点 $$x_i$$ 到超平面的符号距离；
- 分母 $$\|w\|$$ 使得距离规范化为几何距离。

### 最终代码实现

```python
import numpy as np

class PerceptronWithPerceptronLoss:
    def __init__(self, input_dim, learning_rate=0.01):
        self.w = np.random.randn(input_dim) * 0.01 # 初始化随机权重
        self.b = np.random.randn() * 0.01 # 随机初始化偏置
        self.lr = 0.01
    
    # margin: 即使所有样本都被正确分类，也会进行少量训练迭代
    # 这种改动可以让模型在早期训练阶段对靠近分界面的样本进行优化
    # 提升模型的决策边界稳定性。
    def compute_loss(self, X, y, margin=1e-5):
        score = y * (np.dot(X, self.w)+self.b)
        mask = score <= margin
        total_loss = -np.sum(score[mask])
        return total_loss, mask
    
    def update_parameters(self, X, y, mask):
        misclassified_X = X[mask]
        misclassified_y = y[mask]
        self.w += np.sum(misclassified_y[:, None]*misclassified_X, axis=0) * self.lr
        self.b += np.sum(misclassified_y)*self.lr
        print(self.w, self.b)

    def fit(self, X, y, epochs=100, tolerance=1e-4):
        prev_loss = float('inf')
        for epoch in range(epochs):
            loss, mask = self.compute_loss(X, y)
            if loss < tolerance or abs(prev_loss - loss) < tolerance:
                print(f"Converged at epoch {epoch}")
                break
            self.update_parameters(X, y, mask)
            prev_loss = loss
            print(f"Epoch {epoch+1}, Loss {loss}")
    def predict(self, X):
        return np.sign(np.dot(X, self.w)+self.b)
    

X = np.array([[2, 3], [1, 1], [3, 4], [2, 1]])
y = np.array([1, -1, 1, -1])

model = PerceptronWithPerceptronLoss(input_dim=2, learning_rate=0.01)
model.fit(X, y, epochs=50)

print("Final weights:", model.w)
print("Final bias:", model.b)

predicts = model.predict(X)
print("Predict:", predicts)
```

这个实现对原始感知机算法做了一些改进，尤其是引入了 **margin 参数** 来优化模型训练。这可以在训练初期增强模型对靠近决策边界的样本的敏感性，使得模型收敛到更稳健的决策边界。以下是代码运行的关键点和解释：

------

#### **关键点解析**

##### 1. **随机初始化权重和偏置**

```python
self.w = np.random.randn(input_dim) * 0.01
self.b = np.random.randn() * 0.01
```

- 权重 w 和偏置 b被随机初始化为较小值，通常服从标准正态分布再乘以 0.01。
- 这样的初始化避免了原始实现中全零初始化导致的梯度为零问题，同时确保初始状态具有足够的小扰动。

------

##### 2. **加入 margin 参数**

```python
def compute_loss(self, X, y, margin=1e-5):
    score = y * (np.dot(X, self.w) + self.b) # 误分类之后才会出现负数的情况
    mask = score <= margin # 表示误分类的位置
    total_loss = -np.sum(score[mask])
    return total_loss, mask
```

- 作用：
  - 即使所有样本都被正确分类（score > 0），margin 的存在确保决策边界仍然对靠近边界的样本进行优化。
  - 这可以提升模型的泛化能力，使得决策边界更加稳健。

------

##### 3. **参数更新**

```python
def update_parameters(self, X, y, mask):
    misclassified_X = X[mask]
    misclassified_y = y[mask]
    self.w += np.sum(misclassified_y[:, None] * misclassified_X, axis=0) * self.lr
    self.b += np.sum(misclassified_y) * self.lr
```

- **作用：**
  - 仅对误分类或边界附近的样本（由 maskmask 定义）进行权重和偏置更新，提升计算效率。
  - 更新公式遵循感知机规则，即朝误分类样本方向调整决策边界。

------

##### 4. **训练收敛条件**

```python
if loss < tolerance or abs(prev_loss - loss) < tolerance:
    print(f"Converged at epoch {epoch}")
    break
```

- 作用：
  - 当总损失 loss低于设定阈值 tolerance，或者当前损失和上一轮损失的变化幅度小于阈值时，认为模型已收敛。
  - 这种方法可以防止训练陷入无限迭代。

------

##### 5. **预测**

```python
def predict(self, X):
    return np.sign(np.dot(X, self.w) + self.b)
```

- 作用：
  - 根据当前权重和偏置计算每个样本的得分，并通过符号函数 sign(z) 将得分转换为类别标签。

------

#### **运行结果分析**

1. **初始权重和偏置：** 随机初始化导致每次运行结果可能不同，但 margin 的引入确保即便初始值不同，最终模型的表现会较为稳健。

2. **训练过程：**

   - 输出的权重 w 和偏置 b 会逐渐调整，直到所有样本正确分类，或者靠近边界的样本满足 margin 要求。
   - 如果所有样本早期就满足要求，训练过程可能会提前终止。

3. **预测结果：**

   ```python
   Predict: [ 1. -1.  1. -1.]
   ```

   - 说明模型成功学习到数据的线性分割规则。

------

#### **改进后的优点**

- **稳健性提升：** margin 确保模型在早期对靠近决策边界的样本进行优化，增强了分界面的鲁棒性。
- **防止陷入局部最优：** 随机初始化避免权重和偏置均为零时模型无法更新的问题。
- **高效性：** 每次仅更新误分类样本，有效减少无关计算。

### **总结**

- **每次随机初始化会导致训练结果不同，主要因为初始参数影响了优化路径和决策边界的位置。**
- **可以通过固定随机种子、正则化、多次训练取平均等方法减小这种随机性。**
- 如果数据线性可分，不同的随机初始化只会影响最终分界面的具体位置，但所有分界面都能正确分类数据。如果数据不可线性分割，随机初始化的影响会更大，因此可以考虑正则化或改用其他方法。
